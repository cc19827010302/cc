import pandas as pd

# 读取Excel文件
data1 = pd.read_excel('data1.xls')
data2 = pd.read_excel('data2.xls')

import numpy as np

def entropy(data):
    # 计算概率分布
    probabilities = data.value_counts(normalize=True)
    # 计算熵
    entropy = -np.sum(probabilities * np.log2(probabilities))
    return entropy

def mutual_information(x, y):
    # 计算联合分布和边缘分布
    joint_prob = pd.concat([x, y], axis=1).value_counts(normalize=True)
   边缘分布x = x.value_counts(normalize=True)
    边缘分布y = y.value_counts(normalize=True)
    
    # 计算互信息
    mutual_info = np.sum(joint_prob * np.log2((joint_prob / (边缘分布x * 边缘分布y)).values))
    return mutual_info

# 假设data1和data2的第一列是X和Y
H_X = entropy(data1.iloc[:, 0])
H_Y = entropy(data2.iloc[:, 0])
H_XY = entropy(pd.concat([data1.iloc[:, 0], data2.iloc[:, 0]], axis=1))
H_X_given_Y = H_X - mutual_information(data1.iloc[:, 0], data2.iloc[:, 0])
H_Y_given_X = H_Y - mutual_information(data2.iloc[:, 0], data1.iloc[:, 0])
I_XY = mutual_information(data1.iloc[:, 0], data2.iloc[:, 0])

print(f"H(X): {H_X}")
print(f"H(Y): {H_Y}")
print(f"H(X, Y): {H_XY}")
print(f"H(X|Y): {H_X_given_Y}")
print(f"H(Y|X): {H_Y_given_X}")
print(f"I(X, Y): {I_XY}")

